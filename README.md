ğŸ§  AmbedkarGPT â€“ RAG-Based Q&A System

A Submission for the AI Intern Assignment

AmbedkarGPT is a fully offline Retrieval-Augmented Generation (RAG) system that answers questions only from the provided text of Dr. B. R. Ambedkarâ€™s speech.
It uses:

LangChain (latest runnables API)

ChromaDB (local vector store)

HuggingFace sentence-transformers/all-MiniLM-L6-v2

Ollama + Mistral 7B

Python 3.8+

No API keys, no paid services, no external dependencies â€” everything runs locally.

ğŸ“Œ Features

Fully offline RAG pipeline

Local semantic search using ChromaDB

Embeddings powered by MiniLM-L6-v2

Context-aware answers using Mistral (via Ollama)

Simple, clean CLI interface for Q&A

Well-structured, production-ready Python code

100% compliant with assignment instructions

ğŸ“ Project Structure
AmbedkarGPT-Intern-Task/
â”‚
â”œâ”€â”€ data/
â”‚   â””â”€â”€ speech.txt
â”‚
â”œâ”€â”€ src/
â”‚   â””â”€â”€ main.py
â”‚
â”œâ”€â”€ .gitignore
â”œâ”€â”€ requirements.txt
â””â”€â”€ README.md

âš™ï¸ Installation & Setup
1ï¸âƒ£ Clone the repository
git clone https://github.com/<your-username>/AmbedkarGPT-Intern-Task
cd AmbedkarGPT-Intern-Task

2ï¸âƒ£ Create & activate virtual environment
python -m venv venv
.\venv\Scripts\activate       # Windows

3ï¸âƒ£ Install dependencies
pip install -r requirements.txt

ğŸ¤– Install Ollama & Download Mistral 7B
Install Ollama

Download from:
https://ollama.com/download

Pull the model
ollama pull mistral


If mistral fails due to network timeout, pull a smaller fallback:

ollama pull mixtral


Then update in main.py:

model = Ollama(model="mixtral")

â–¶ï¸ Running the Application

Start the CLI chatbot:

python src/main.py


Example interaction:

> What does Ambedkar identify as the root cause of caste?

--- Answer ---
Ambedkar argues that the root cause of caste is the belief in the sanctity and infallibility of the shastras.

ğŸ§¬ How the RAG Pipeline Works

The system follows a modern RAG architecture:

Load the input text (speech.txt)

Split into manageable chunks (300 chars + overlap)

Generate embeddings using MiniLM

Store vectors locally using ChromaDB

Convert user query â†’ embedding

Retrieve top 3 most relevant chunks

Insert context + question into a prompt template

Send prompt to Mistral via Ollama

Return a grounded, accurate answer

This ensures zero hallucination and completely local inference.

ğŸ—‚ Deliverables (as per assignment)

âœ” main.py â€” fully commented, clean Python code

âœ” requirements.txt â€” contains all dependencies

âœ” speech.txt â€” provided speech file

âœ” README.md â€” detailed setup + technical explanation

âœ” Public GitHub repository named AmbedkarGPT-Intern-Task

ğŸ“œ License

This project is created solely for the intern assignment and educational purposes.